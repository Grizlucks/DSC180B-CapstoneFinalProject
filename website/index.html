<!DOCTYPE HTML>
<!--
	Paradigm Shift by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Gender Bias in AI Generated Images</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
					<section class="intro">
						<header>
							<h1>Gender Bias in AI Generated Images</h1>
							<p>Are different genders fairly represented when generating images using OpenAI's Dall-E-2 text-to-image platform?</p>
							<ul class="actions">
								<li><a href="#first" class="arrow scrolly"><span class="label">Next</span></a></li>
							</ul>
						</header>
						<div class="content">
							<span class="image fill" data-position="center"><img src="images/2x-no-mark.jpg" alt="" /></span>
						</div>
					</section>

				<!-- Section -->
					<section id="first">
						<header>
							<h2>Abstract</h2>
						</header>
						<div class="content">
							<p>
								DALL-E 2 is a model that processes natural language and returns a corresponding image or set of images. This model has in the past several years come under increasing scrutiny due to its biased results wherein certain genders or races are displayed more, often significantly more, than others. In July of 2022, OpenAI, the publishers of DALL-E 2, revealed that they had worked on methods to mitigate this bias that had resulted in a marked and visible improvement in the result sets. This is the claim that was tested over the course of this investigation; is DALL-E 2 still biased in terms of occupational gender bias? In other words, are the image sets generated by the algorithm relatively balanced? In order to test this claim, ten professions were selected from the Bureau of Labor Statistics listing of occupations in the United States. Half were selected as slightly male dominated (over 50% of the gender make up for the job was male), the other half were selected as slightly female dominated professions. Upon testing these inputs through DALL-E 2 and tagging the resulting images as either male or female, it was found that, if not the model itself, the DALL-E 2 API is still extremely biased at least across the axis of gender.

							</p>
							
						</div>
					</section>

					<!-- Section -->
					<section>
						<header>
							<h2>Introduction</h2>
						</header>
						<div class="content">
							<p>
								Since the invention of the multi-layer perceptron network, there has never been a time when AI has been more prevalent or visible in our society than the present day. Machine learning is used for almost everything; healthcare, business analytics, correctional systems, scientific exploration, and even in seemingly mild and light hearted applications that have achieved widespread commercial and critical success. One of these applications is the image generating model known colloquially as ‘DALL-E 2’, a software that receives prompts in the form of natural language and outputs its own perception of what the user wants to see. At first glance this seems completely fangless and friendly. However, as other investigations have demonstrated, this is clearly and concisely not the case. 
								<br><br>
								DALL-E 2 has recently come under fire for the racial and gender make-up of its outputs when given specific prompts. For instance, and this will be covered more in the literature review section, when asked to generate images of CEOs, DALL-E 2 will show only pictures of straight white men. This is a problem, and one that they have apparently been working to address. 

							</div>
						</section>						
								

							<!-- Section -->
					<section>
						<header>
							<a href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/" target="_blank"><h3><u>OpenAi's claimed bias mitigation techniques as of July 2022</u></h3></a>
						</header>
						<div class="content">
							<p>
						
						<a href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/" target="_blank"><img src="images/openai.png" alt="" /></a>
								

								<br><br>
								<strong>In this project, we will investigate just how far the team at OpenAI has come in terms of bias mitigation by examining the outputs of several different prompts that have been passed through their image generation software. </strong>
									
							</p>

						</div>
					</section>		
							


					<!-- Section -->
					<section>
						<header>
							<h2>Experiment Process</h2>
						</header>
						<div class="content">
							<p>
								The first step was to find a statistically robust and reputable source from which to derive the prompts. Ultimately the source chosen was the US Bureau of Labor Statistics (BLS) and 
								specifically their <a href="https://www.bls.gov/cps/" target="_blank"><strong>‘Labor Force Statistics from the Current Population Survey’.</strong></a> Once this source was found, and prompts could be generated, the actual investigation could begin.
								<br><br>
								Upon finding a good source to obtain prompts from, the next step was deciding what was meant by an ‘unbiased resultset’. Here there were two options; first to use the actual statistical percentage of each gender in the position as a benchmark for ‘unbiased’, and second to use a more ideal and representative benchmark of 50-50; that is to say half of the images were expected to be feminine-presenting and the other half were expected to be masculine-presenting. The second option was deemed superior (in simple terms because reflecting the bias of the real world is the precursor to representative harms; this will be discussed in depth in later sections of this report). 
								<br><br>
								Once this benchmark was selected, the next step was to determine how many and which prompts to pass through DALL-E 2. The first consideration here was the previously mentioned hard limit of ninety dollars which could not be exceeded. The second consideration was ensuring that DALL-E 2 was not biased towards or against either gender in particular. The third consideration was determining how large of a sample would be necessary in order to arrive at a robust and statistically sound conclusion that made sense. 
								<br><br>
								It also became apparent that choosing occupations with a particularly heavy bias would be too trivial; these occupations demanded a minute sample size, but were also deemed low hanging fruit, in the sense that the internal bias in DALL-E 2 would not truly be tested if these were the prompts selected. As such the fourth and final constraint was to choose prompts such that each occupation could have no more than 65% of its survey respondents dominated by a single gender.
								<br><br>
								With these parameters in mind, the first task was examining how large of a sample would be necessary for each of the occupations in the BLS data. This was calculated using the one-sample dichotomous outcome formula mentioned in the reference section below. Once these sample sizes were calculated, it became apparent that a good sample size to use across the board was 206 images per occupation; this was the highest number of samples demanded by an occupation in order to conduct this statistical test. This also meant that only ten occupations could be selected for investigating DALL-E 2.
								<br><br>
								In accordance with the second parameter listed above, five of those occupations were selected as female-dominated while the remaining five were selected as male-dominated.
								<br><br>
								Ultimately the ten occupations selected as prompts can be seen in the figure below along with the percentage of females within each occupation, as determined by the BLS data:
							</p>
						</div>
					</section>	
								

					
					<!-- Section -->
					<section>
						<header>
							<h3>Table 1: The ten occupations selected as prompts for DALL-E 2 along with the number of BLS survey respondents and the percentage of non-male respondents</h3>
						</header>
						<div class="content">
							<p>
								<table>
									<tr>
										
										<td><strong>Occupation</strong></td>
										<td><strong>N</strong></td>
										<td><strong>% Non-Male</strong></td>
										
									</tr>

									<tr>
										<td>Financial/Investment Analysts</td>
										<td>387</td>
										<td>40.2</td>
									</tr>

									<tr>
										<td>Janitors/Building Cleaners</td>
										<td>2183</td>
										<td>40.2</td>
									</tr>

									<tr>
										<td>Lawyers</td>
										<td>1141</td>
										<td>38.5</td>
									</tr>

									<tr>
										<td>Cooks</td>
										<td>2012</td>
										<td>38.4</td>
									</tr>

									<tr>
										<td>Dentists</td>
										<td>140</td>
										<td>36.6</td>
									</tr>

									<tr>
										<td>Bartenders</td>
										<td>457</td>
										<td>59</td>
									</tr>

									<tr>
										<td>Biological Scientists</td>
										<td>110</td>
										<td>57.9</td>
									</tr>

									<tr>
										<td>Secondary School Teachers</td>
										<td>1000</td>
										<td>58.7</td>
									</tr>

									<tr>
										<td>Pharmacists</td>
										<td>375</td>
										<td>59.6</td>
									</tr>

									<tr>
										<td>Trainers/Fitness Instructors</td>
										<td>234</td>
										<td>62.9</td>
									</tr>

								</table>
								
							</p>
							
						</div>
					</section>

					<!-- Section -->
					<section>
						<header>
							<h2>Results</h2>
						</header>
						<div class="content">
							<p>
								<div class="gallery">
									<a href="images/cook.png"><img src="images/cook.png" alt="" /></a>
									<a href="images/financial_analyst.png"><img src="images/financial_analyst.png" alt="" /></a>
									<a href="images/secondary_school_teacher.png"><img src="images/secondary_school_teacher.png" alt="" /></a>
									<a href="images/bartender.png"><img src="images/bartender.png" alt="" /></a>
								</div>
							</p>
							
						</div>
					</section>

					<!-- Section -->
					<section>
						<header>
							<h2>Conclusion</h2>
						</header>
						<div class="content">
							<p>
								
							</p>
							
						</div>
					</section>
			
				<!-- Copyright -->
					<div class="copyright">&copy; DSC 180B: Winter 2023<br>
					James Dai, Vedan Desai, Moses Oh, Costin Smilovici, Tyler Tran
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>